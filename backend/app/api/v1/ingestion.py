from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from pydantic import BaseModel
from typing import List

from app.db.session import get_db
from app.models.run import Run
from app.models.failure import Failure
from app.models.label import Label

from app.parsers.normalize import normalize_message
from app.ml.inference import classify_message

router = APIRouter()

#request models
#this will define what each failure object must contain basically all the columns for failure_id:1
class FailureItem(BaseModel):
    test_name: str
    raw_message: str
    platform: str            # "desktop" / "mobile"
    website: str             # domain only (ex: indianexpress.com)

#this is the toplevel request which fastapi uses to validate incoming JSON
class IngestionRequest(BaseModel):
    run_id: str              # external pipeline run ID
    jenkins_job: str
    website: str             # main website for this run
    failures: List[FailureItem]


#ingest api POST endpoint, fastapi will parse this JSON into the above mentioned class
@router.post("/")
def ingest_failure_report(payload: IngestionRequest, db: Session = Depends(get_db)):
    """
    Receives a run + list of failures
    → Normalize, classify, store in DB
    → Returns run info + classification
    """

    #creating a run entry, meaning the id of build that ran and reported error, with its parameters such as job_name, jenkins_server etc.
    run = Run(
        run_uid=payload.run_id,
        job_name=payload.jenkins_job,
        jenkins_server="local",
        website_id=None,     # until Website table integration
        build_number=None,
        status="FAILED",
    )

    db.add(run) #here, the above created run object, meaning row, will be added to db session.
    db.commit() #a row will be written that contains RUN data.
    db.refresh(run) #reloading objects from DB so that autogenerated primary key is automatically populated e.g. id

    #processing the each failure
    results = []
    for f in payload.failures:
        try:
            #normalizing message; cleaning raw text, remove noise, stack_trace etc.
            normalized = normalize_message(f.raw_message)

            #ML classification; this will return label and confidence score, which are part of this app's parsing/ML pipeline.
            label, confidence = classify_message(normalized)

            #creating failure entry just as we created run entry above
            failure = Failure(
                run_id=run.id, #relation link to the Run
                test_name=f.test_name,
                platform=f.platform,
                website=f.website,
                error_message=normalized,
                extracted_message=normalized.split(":")[0],  # simple extraction
                website_id=None
            )
            db.add(failure)
            db.commit()
            db.refresh(failure) #a new failure row is made and stored

            #same as the above row creations, this will link ML lable+confidence to stored failure
            label_row = Label(
                failure_id=failure.id,
                label=label,
                confidence=confidence,
                source="model",
                labeled_by="model_v1"
            )
            db.add(label_row)
            db.commit()

            #append to response list
            results.append({
                "failure_id": failure.id,
                "test_name": f.test_name,
                "normalized": normalized,
                "label": label,
                "confidence": confidence
            }) #basically, collecting a dictionary for each processed failure to be returned in the final JSON response

        except Exception as e:
            #log error and continue with next failure
            print(f"[INGEST ERROR] Failed to store failure: {str(e)}")
            continue

    #returning json object that summarizes the run and produced labels.
    return {
        "run_internal_id": run.id,
        "external_run_id": payload.run_id,
        "website": payload.website,
        "total_received": len(payload.failures),
        "classified": results
    }
